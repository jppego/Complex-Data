{"cells":[{"cell_type":"markdown","metadata":{"id":"kxZwmwOpfVA0"},"source":["# Import modules"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":636,"status":"ok","timestamp":1670889036908,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"Txz6zxEDfVA5"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"LsduXttWfVA7"},"source":["# Mount google drive"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20818,"status":"ok","timestamp":1670889057715,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"SMUriY0KfVA7","outputId":"e7c91d10-7bef-446d-888e-9589bb16734a"},"outputs":[],"source":["# References:\n","# [1] https://towardsdatascience.com/different-ways-to-connect-google-drive-to-a-google-colab-notebook-pt-1-de03433d2f7a\n","# [2] https://stackoverflow.com/questions/54351852/accessing-shared-with-me-with-colab\n","# [3] https://stackoverflow.com/questions/53581278/test-if-notebook-is-running-on-google-colab\n","\n","try:\n","    from google.colab import drive\n","    from google.colab import files\n","    # import torch\n","    # import torch.nn as nn\n","    # import torch.nn.functional as F\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False\n","\n","if IN_COLAB:\n","\n","    # mount google drive \n","    drive.mount('/content/gdrive/', force_remount=True)\n","\n","    import os\n","    #change directory\n","    try:\n","        os.chdir('/content/gdrive/MyDrive/MCED/ADC')\n","\n","    except:\n","        os.chdir('/content/gdrive/MyDrive/ADC')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1670889058023,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"NmAtpMJJfVA8","outputId":"4e9df8da-f1c8-4a5a-faf2-5d9977204c50"},"outputs":[{"data":{"text/plain":["'h:\\\\My Drive\\\\MCED\\\\ADC'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# working directory\n","wdir = os.getcwd()\n","\n","wdir"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":261,"status":"ok","timestamp":1670889067154,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"8ZikxkR0fVA-"},"outputs":[],"source":["# https://www.tutorialspoint.com/python_data_science/python_reading_html_pages.htm\n","from bs4 import BeautifulSoup\n","import re\n","import time\n","# import random\n","import requests\n","\n","def extract_links(page, cookies, headers, data):\n","\n","\n","    # print(f'Processing page {page}')\n","    params = {\n","        'formname': 'SORT',\n","        'actualPage': str(page),\n","    }\n","    \n","    response = requests.post('https://www.rcaap.pt/search', cookies=cookies, headers=headers, data=data)\n","    response = requests.get('https://www.rcaap.pt/search', params=params, cookies=cookies, headers=headers)\n","    \n","\n","    # html content\n","    html_doc = response.content\n","\n","    # Parse the html file\n","    soup = BeautifulSoup(html_doc, 'html.parser')\n","\n","    # Format the parsed html file\n","    strhtm = soup.prettify()\n","\n","    # Print the first few characters\n","    # print (strhtm)\n","\n","    # https://stackoverflow.com/questions/32680030/match-text-between-two-strings-with-regular-expression\n","    urls = re.findall(r'detail.jsp\\?id=oai:(.*?)\" title=' , strhtm)\n","\n","    return urls"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1670889070476,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"RQ4VdG6afVA_"},"outputs":[],"source":["\n","dict_unis = {\n","       'UPorto'    : \"rabertoup\",          # \"Repositório Aberto da Universidade do Porto (34682)\"\n","       'UCoimbra'  : \"estudogl\",           # \"Estudo Geral - Universidade de Coimbra (20368)\"\n","       'ULisboa'   : \"ul\",                 # \"Repositório da Universidade de Lisboa (17436)\"\n","       'UNLisboa'  : \"run\",                # \"Repositório Institucional da UNL (14415)\"\n","       'UMinho'    : \"rum\",                # \"RepositóriUM - Universidade do Minho (13845)\"\n","       'UAveiro'   : \"ria\",                # \"RIA - Repositório Institucional da Universidade de Aveiro (13254)\"\n","       'UTL'       : \"rutl\",               # \"Repositório da UTL (12863)\"\n","       'UCP'       : \"veritati\",           # \"Veritati - Repositório Institucional da Universidade Católica Portuguesa (9289)\"\n","       'ISCTE'     : \"iscte\",              # \"Repositório ISCTE (8605)\"\n","       'IPPorto'   : \"recipp\",             # \"Repositório Científico do Instituto Politécnico do Porto (7858)\"\n","       'UBI'       : \"ubibliorum\",         # \"uBibliorum (6998)\"\n","       'UÉvora'    : \"uevora\",             # \"Repositório Científico da Universidade de Évora (5980)\"\n","       'UTAD'      : \"utad\",               # \"Repositório da UTAD (5525)\"\n","       'IPLisboa'  : \"ripl\",               # \"Repositório Científico do Instituto Politécnico de Lisboa (5232)\"\n","       'Lusófona'  : \"recil\",              # \"ReCiL - Repositório Científico Lusófona (5002)\"\n","       'UFPessoa'  : \"ufp\",                # \"Repositório Institucional - Universidade Fernando Pessoa (4170)\"\n","       'UAlg'      : \"sapientia\",          # \"Sapientia - Universidade do Algarve (3643)\"\n","       'ISPA'      : \"ispa\",               # \"Repositório do ISPA - Instituto Universitário (3367)\"\n","       'IPCoimbra' : \"ipc\",                # \"Instituto Politécnico de Coimbra (3053)\"\n","       'ICOnline'  : \"iconline\"            # \"IC-online (2688)\"\n","       }\n","       \n","dict_npages = {\n","       'UPorto'    : 3469, \n","       'UCoimbra'  : 2037,\n","       'ULisboa'   : 1744,\n","       'UNLisboa'  : 1442, \n","       'UMinho'    : 1385,\n","       'UAveiro'   : 1326, \n","       'UTL'       : 1287, \n","       'UCP'       : 929,\n","       'ISCTE'     : 861,\n","       'IPPorto'   : 786, \n","       'UBI'       : 700,\n","       'UÉvora'    : 599,\n","       'UTAD'      : 553,\n","       'IPLisboa'  : 524,\n","       'Lusófona'  : 501,\n","       'UFPessoa'  : 418,\n","       'UAlg'      : 365,\n","       'ISPA'      : 337,\n","       'IPCoimbra' : 306,\n","       'ICOnline'  : 269\n","       }\n","\n","dict_repository = {\n","       'UPorto'    : 'repositorio-aberto.up.pt', \n","       'UCoimbra'  : 'estudogeral.sib.uc.pt',\n","       'ULisboa'   : 'repositorio.ul.pt',\n","       'UNLisboa'  : 'run.unl.pt', \n","       'UMinho'    : 'repositorium.sdum.uminho.pt',\n","       'UAveiro'   : 'ria.ua.pt', \n","       'UTL'       : 'www.repository.utl.pt', \n","       'UCP'       : 'repositorio.ucp.pt',\n","       'ISCTE'     : 'repositorio.iscte-iul.pt',\n","       'IPPorto'   : 'recipp.ipp.pt', \n","       'UBI'       : 'ubibliorum.ubi.pt',\n","       'UÉvora'    : 'dspace.uevora.pt',\n","       'UTAD'      : 'repositorio.utad.pt',\n","       'IPLisboa'  : 'repositorio.ipl.pt',\n","       'Lusófona'  : 'recil.ensinolusofona.pt',\n","       'UFPessoa'  : 'bdigital.ufp.pt',\n","       'UAlg'      : 'sapientia.ualg.pt',\n","       'ISPA'      : 'repositorio.ispa.pt',\n","       'IPCoimbra' : 'comum.rcaap.pt',\n","       'ICOnline'  : 'iconline.ipleiria.pt'\n","       }"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1670889073793,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"2YCXgdkEfVBA"},"outputs":[],"source":["def form_data(uni_code):\n","\n","\n","    cookies = {\n","        'JSESSIONID': '86764D6305741E8A33E1E7AD9DFC9A7D',\n","        'locale': 'pt',\n","        '__utma': '22998072.296766937.1671061168.1671061168.1671061168.1',\n","        '__utmb': '22998072.5.10.1671061168',\n","        '__utmc': '22998072',\n","        '__utmz': '22998072.1671061168.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none)',\n","        '__utmt': '1',\n","    }\n","\n","    headers = {\n","        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0',\n","        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n","        'Accept-Language': 'en-US,en;q=0.5',\n","        # 'Accept-Encoding': 'gzip, deflate, br',\n","        'Referer': 'https://www.rcaap.pt/search.jsp',\n","        'Origin': 'https://www.rcaap.pt',\n","        'Connection': 'keep-alive',\n","        # 'Cookie': 'JSESSIONID=86764D6305741E8A33E1E7AD9DFC9A7D; locale=pt; __utma=22998072.296766937.1671061168.1671061168.1671061168.1; __utmb=22998072.5.10.1671061168; __utmc=22998072; __utmz=22998072.1671061168.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utmt=1',\n","        'Upgrade-Insecure-Requests': '1',\n","        'Sec-Fetch-Dest': 'document',\n","        'Sec-Fetch-Mode': 'navigate',\n","        'Sec-Fetch-Site': 'same-origin',\n","        'Sec-Fetch-User': '?1',\n","    }\n","\n","\n","    data = {\n","        'formname': 'ADVANCED',\n","        'includeAll': 'no',\n","        'col1': 'title.main',\n","        'col_val1': '',\n","        'op2': 'AND',\n","        'col2': 'contributor.all',\n","        'col_val2': '',\n","        'op3': 'AND',\n","        'col3': 'subject.all',\n","        'col_val3': '',\n","        'btnSearch': 'Pesquisar',\n","        'orderBy': 'ISSUE_DATE',\n","        'orderType': 'DESC',\n","        'since': '1806',\n","        'until': '2302',\n","        'funder_acronym': '',\n","        'funding_program': '',\n","        'project_id': '',\n","        'type.coar': 'http://purl.org/coar/resource_type/c_bdcc',\n","        'language': 'por',\n","        'network_acronym_str': uni_code,\n","    }\n","\n","    return cookies, headers, data\n","\n","# response = requests.post('https://www.rcaap.pt/search', cookies=cookies, headers=headers, data=data)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":261,"status":"ok","timestamp":1670889078415,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"7iq7JX5pfVBB"},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","\n","def fetch_pages(l_missing, l_pages, niter, university, fname, cookies, headers, data):\n","\n","    l_failures = []\n","\n","    for iter in tqdm(range(len(l_missing))):\n","\n","        page = l_missing[iter]\n","        \n","        if iter > 0 and iter // 10:\n","            df_urls = pd.DataFrame(l_pages)\n","            df_urls.to_csv(fname, index=False)\n","            # time.sleep(2)\n","\n","\n","        urls = extract_links(page, cookies, headers, data)\n","\n","        if len(urls) == 0:\n","            l_failures.append(page)\n","            # print(f'Page {page} was not retrieved')\n","            continue\n","            \n","        dict_urls = {'page' : page, 'urls' : urls}\n","\n","        l_pages.append(dict_urls)\n","\n","        # time.sleep(10)\n","\n","    return l_pages, l_failures, df_urls\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1670889082723,"user":{"displayName":"João Pedro Pêgo","userId":"04680859484862327761"},"user_tz":0},"id":"nGy6wzqFfVBC"},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","\n","def fetch_failures(l_missing, l_pages, niter, university, fname, cookies, headers, data):\n","\n","    print(f'{len(l_missing)} pages were not retrieved. Second atempt.')\n","\n","\n","    l_failures = []\n","    \n","    for iter in tqdm(range(len(l_missing))):\n","\n","        page = l_missing[iter]\n","\n","        urls = extract_links(page, cookies, headers, data)\n","\n","        if len(urls) == 0:\n","            urls = extract_links(page, cookies, headers, data)\n","            # print(f'Trying to retrieve page {page} again.')\n","\n","        if len(urls) == 0:\n","            # print(f'Page {page} was not retrieved.')\n","            l_failures.append(page)\n","            \n","            \n","        dict_urls = {'page' : page, 'urls' : urls}\n","\n","        l_pages.append(dict_urls)\n","\n","    df_urls = pd.DataFrame(l_pages).sort_values(by = 'page', ascending = True)\n","    df_urls.to_csv(fname, index= False)\n","\n","    return df_urls, l_failures\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CqgmiAT8fVBD","outputId":"91d3f011-465f-4bad-8132-2dc6390ae896"},"outputs":[{"data":{"text/plain":["dict_keys(['UPorto', 'UCoimbra', 'ULisboa', 'UNLisboa', 'UMinho', 'UAveiro', 'UTL', 'UCP', 'ISCTE', 'IPPorto', 'UBI', 'UÉvora', 'UTAD', 'IPLisboa', 'Lusófona', 'UFPessoa', 'UAlg', 'ISPA', 'IPCoimbra', 'ICOnline'])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["l_unis = dict_npages.keys()\n","l_unis"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MjBTP3eSfVBE"},"outputs":[],"source":["l_unis = ['ICOnline']"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ScWcE9rDfVBE","outputId":"51f76325-e860-4c68-f2fb-9c26e90cafbd"},"outputs":[],"source":["\n","def webscrapper(l_unis):\n","\n","    l_errors = []\n","\n","    for university in l_unis:\n","        \n","        print(f'Fecthing pages from {university}')\n","        \n","        uni_code = dict_unis[university]\n","\n","        cookies, headers, data = form_data(uni_code)\n","\n","        page_init = 1\n","        # niter = 20\n","        niter = dict_npages[university]\n","\n","        fname = 'df_urls_' + university + '_.csv'\n","\n","        l_pages = []\n","        l_missing = [i for i in range(1, page_init + niter)]\n","\n","        l_pages, l_failures, df_urls = fetch_pages(l_missing, l_pages, niter, university, fname, cookies, headers, data)\n","\n","        df_urls, l_failures = fetch_failures(l_failures, l_pages, niter, university, fname, cookies, headers, data)\n","\n","        dict_error = {'university': university, 'failures' : l_failures}\n","\n","        l_errors.append(dict_error)\n","\n","    df_failures = pd.DataFrame(l_errors)\n","    df_failures.to_csv('df_failures.csv', index=False)\n","\n","    return df_failures"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["university = 'UPorto'\n","\n","def corr_df_urls(university):\n","\n","    print(f'Correcting errors  from {university}')\n","\n","    fname = 'df_urls_' + university + '.csv'\n","\n","    df_urls = pd.read_csv('DF_URLS/' + fname)\n","\n","    uni_code = dict_unis[university]\n","\n","    cookies, headers, data = form_data(uni_code)\n","\n","    repository = dict_repository[university]\n","\n","    length = len(repository)\n","\n","    # creates a df of pages which have not been correctly downloaded\n","    df_errors = df_urls[df_urls['urls'].apply(lambda x: True if x[2:2+length] != repository else False)]\n","\n","    # creates a list of pages which have not been correctly downloaded\n","    l_errors = df_errors.page.to_list()\n","\n","    print(f'{len(l_errors)} errors detected in {university} dataframe.')\n","\n","    if len(l_errors) > 0:\n","        l_pages = []\n","        l_failures = []\n","\n","        for page in tqdm(l_errors):\n","\n","            urls = extract_links(page, cookies, headers, data)\n","\n","            time.sleep(0.2)\n","\n","            if len(urls) == 0:\n","                urls = extract_links(page, cookies, headers, data)\n","                # print(f'Trying to retrieve page {page} again.')\n","\n","            if len(urls) == 0:\n","                # print(f'Page {page} was not retrieved.')\n","                l_failures.append(page)\n","                \n","                \n","            dict_urls = {'page' : page, 'urls' : urls}\n","\n","            l_pages.append(dict_urls)\n","\n","        df_corr = pd.DataFrame(l_pages).sort_values(by = 'page', ascending = True)\n","\n","        df_corr.head()\n","\n","        df_urls = df_urls[~df_urls['page'].isin(l_errors)]\n","\n","        # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n","        df_final = pd.concat([df_urls, df_corr]).sort_values(by = 'page', ascending = True)\n","\n","        fname = 'df_urls_' + university + '_corr.csv'\n","        df_final.to_csv(fname, index= False)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Correcting errors  from UPorto\n","30 errors detected in UPorto dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UCoimbra\n","14 errors detected in UCoimbra dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14/14 [00:18<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from ULisboa\n","16 errors detected in ULisboa dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [00:20<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UNLisboa\n","11 errors detected in UNLisboa dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11/11 [00:13<00:00,  1.24s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UMinho\n","6 errors detected in UMinho dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UAveiro\n","6 errors detected in UAveiro dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UTL\n","6 errors detected in UTL dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [00:08<00:00,  1.39s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UCP\n","4 errors detected in UCP dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from ISCTE\n","2 errors detected in ISCTE dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:03<00:00,  1.53s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from IPPorto\n","3 errors detected in IPPorto dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:03<00:00,  1.24s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UBI\n","8 errors detected in UBI dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:09<00:00,  1.16s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UÉvora\n","6 errors detected in UÉvora dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UTAD\n","1 errors detected in UTAD dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from IPLisboa\n","1 errors detected in IPLisboa dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from Lusófona\n","1 errors detected in Lusófona dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UFPessoa\n","1 errors detected in UFPessoa dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Correcting errors  from UAlg\n","0 errors detected in UAlg dataframe.\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n"]},{"ename":"KeyError","evalue":"'page'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m university \u001b[39min\u001b[39;00m dict_repository:\n\u001b[1;32m----> 3\u001b[0m     corr_df_urls(university)\n","Cell \u001b[1;32mIn[16], line 50\u001b[0m, in \u001b[0;36mcorr_df_urls\u001b[1;34m(university)\u001b[0m\n\u001b[0;32m     46\u001b[0m     dict_urls \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpage\u001b[39m\u001b[39m'\u001b[39m : page, \u001b[39m'\u001b[39m\u001b[39murls\u001b[39m\u001b[39m'\u001b[39m : urls}\n\u001b[0;32m     48\u001b[0m     l_pages\u001b[39m.\u001b[39mappend(dict_urls)\n\u001b[1;32m---> 50\u001b[0m df_corr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(l_pages)\u001b[39m.\u001b[39;49msort_values(by \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mpage\u001b[39;49m\u001b[39m'\u001b[39;49m, ascending \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     52\u001b[0m df_corr\u001b[39m.\u001b[39mhead()\n\u001b[0;32m     54\u001b[0m df_urls \u001b[39m=\u001b[39m df_urls[\u001b[39m~\u001b[39mdf_urls[\u001b[39m'\u001b[39m\u001b[39mpage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(l_errors)]\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sklearn-env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sklearn-env\\lib\\site-packages\\pandas\\core\\frame.py:6909\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6905\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(by):\n\u001b[0;32m   6906\u001b[0m     \u001b[39m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   6908\u001b[0m     by \u001b[39m=\u001b[39m by[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 6909\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(by, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   6911\u001b[0m     \u001b[39m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[0;32m   6912\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6913\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m   6914\u001b[0m         \u001b[39m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\sklearn-env\\lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n","\u001b[1;31mKeyError\u001b[0m: 'page'"]}],"source":["for university in dict_repository:\n","\n","    corr_df_urls(university)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLEiz5UGfVBE"},"outputs":[],"source":["# import re\n","# from robobrowser import RoboBrowser\n","# import werkzeug\n","# # https://stackoverflow.com/questions/38411942/anaconda-conda-install-a-specific-package-version\n","# # from werkzeug.utils import cached_property\n","\n","\n","# # Browse to Rap Genius\n","# browser = RoboBrowser(history=True)\n","# browser.open('http://rapgenius.com/')\n","\n","# # Search for Queen\n","# form = browser.get_form(action='/search')\n","# form                # <RoboForm q=>\n","# form['q'].value = 'queen'\n","# browser.submit_form(form)\n","\n","# # Look up the first song\n","# songs = browser.select('.song_name')\n","# browser.follow_link(songs[0])\n","# lyrics = browser.select('.lyrics')\n","# lyrics[0].text      # \\n[Intro]\\nIs this the real life...\n","\n","# # Back to results page\n","# browser.back()\n","\n","# # Look up my favorite song\n","# browser.follow_link('death on two legs')\n","\n","# # Can also search HTML using regex patterns\n","# lyrics = browser.find(class_=re.compile(r'\\blyrics\\b'))\n","# lyrics.text         # \\n[Verse 1]\\nYou suck my blood like a leech..."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":0}
